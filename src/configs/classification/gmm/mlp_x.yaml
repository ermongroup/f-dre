training:
  batch_size: 128
  n_epochs: 15
  ngpu: 1
  iter_log: 1000
  iter_save: 100
  exp_id: "gmm_clf_x"
  out_dir: "/path/to/f-dre/src/classification/results/"
  data_dir: "/path/to/f-dre/data/"

data:
  dataset: "GMM"
  subset: false
  x_space: true
  input_size: 2
  perc: 1.0
  mus: [0, 3]
  class_idx: 20
  num_workers: 4

model:
  name: "mlp"
  spectral_norm: true
  batch_norm: true
  in_dim: 2
  h_dim: 200
  dropout: 0.1
  n_classes: 2

optim:
  weight_decay: 0.000
  optimizer: "Adam"
  lr: 0.0002
  beta1: 0.9
  amsgrad: false

loss:
  name: "bce"
  alpha: 100